# Courses

## CS Basics

### Stanford CS106B/X: Programming Abstractions in C++

* Recordings for [Winter 2018](https://b23.tv/UqMrduS)
* Lecture Slides for [Summer 2019](ttps://web.stanford.edu/class/archive/cs/cs106b/cs106b.1198/)
* Programming Assignments for [Spring 2017](https://web.stanford.edu/class/archive/cs/cs106b/cs106b.1176)
* [Official Lecture Notes](https://web.stanford.edu/class/cs106x/res/reader/CS106BX-Reader.pdf) are already downloaded.
* [Estimated Time](https://csdiy.wiki/编程入门/cpp/CS106B_CS106X/): 50-70 hrs

### UCB CS61A: Structure and Interpretation of Computer Programs

* [overview](https://csdiy.wiki/编程入门/Python/CS61A/)

### UCB CS61B: Data Structures and Algorithms

* [overview](https://csdiy.wiki/数据结构与算法/CS61B/)

## ML/DL

### Stanford CS229 by Andrew Ng in [Fall 2022](https://cs229.stanford.edu/syllabus-fall2022.html)

### Deep Learning Specialization by Andrew Ng

* [Official Website](https://www.coursera.org/specializations/deep-learning) on Coursera
* [Recording 1, with clean captions](https://b23.tv/th0i9h9) vs [Recording 2, with Transformer included at the end](https://b23.tv/BZ6Vbuv)
* [Empty Programming Assignments](https://github.com/tcmyxc/DL-AndrewNg) since 2021 (based on Tensorflow v2.0+) with [Solutions](https://github.com/abdur75648/Deep-Learning-Specialization-Coursera)
* [Solutions to Previous PAs](https://github.com/amanchadha/coursera-deep-learning-specialization/tree/master) 
* Extended Readings: [Course Materials](https://github.com/maxim5/cs230-2018-autumn) of [CS230](https://cs230.stanford.edu) in Fall 2018 by Andrew Ng. The materials are very practical and the Stanford course website is helpful.

### NTU Machine Learning by Hung-yi Lee

* Offered in Spring 2022 
* Everything is available on the [Official Website](https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php) (probably the most useful course website).
* [Course GitHub Repository](https://github.com/virginiakm1988/ML2022-Spring)

### Stanford CS224W Machine Learning with Graphs by Jure Leskovec

* [Official Website](https://web.stanford.edu/class/cs224w/)
* [Recording 1 on YouTube](https://youtube.com/playlist?list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn&si=Y40IO58egTtWJeT1) vs [Recording 2 on Bilibili](https://b23.tv/ujrFsiR)
* [Course Note 1 for Fall 2019](https://jingboyang.github.io/cs224w_notes.html) vs [Official Course Note for Fall 2019](https://snap-stanford.github.io/cs224w-notes/)
* Solutions to PAs (5 Colabs) in [Winter 2021](), [Fall 2021](https://github.com/MartinLwx/CS224W-Fall-2021-Stanford), and a [Rough Overview](https://github.com/YZ-Cai/Colabs-CS224W-Machine-Learning-with-Graphs) of these 5 Colabs
* Other versions of solutions can be found on [GitHub](https://github.com/topics/cs224w)
* Slides and Homework (in LaTex) for [Winter 2023 (with many Guest Lecturers)](https://snap.stanford.edu/class/cs224w-2023/index.html#schedule)  offering are downloaded.
* Notice that this course was "completely re-designed" by [Jiaxuan You](https://cs.stanford.edu/~jiaxuan/) in [2021](http://snap.stanford.edu/class/cs224w-2020/)
* Notice that at Stanford, the Winter semester starts in January and ends in March. So Winter comes earlier than Fall there.



# Papers

## Classics in History (Sorted in Ascending Order by Year Published)

### Bleu: a Method for Automatic Evaluation of Machine Translation

* ACL 2002
* [**BLEU**](https://aclanthology.org/P02-1040/) is a commonly used scoring method in machine translation. 
* Andrew Ng said this paper is easy to read.

### Neural Machine Translation by Jointly Learning to Align and Translate

* ICLR 2015
* The [**Attention Mechanism**](https://arxiv.org/abs/1409.0473) (foundation of Transformer) was first proposed here.
* Extended reading: [**Visual Attention**](https://arxiv.org/abs/1502.03044) in image caption.
* Yoshua Bengio (the corresponding author) won the Turing Award with Geoffrey Hinton and Yann LeCun for their contribution to deep learning.

### Deep Residual Learning for Image Recognition

* Proposed [**ResNet**](https://arxiv.org/abs/1512.03385).
* Notice that Kaiming He graduated from Zhixin Middle School.

### Attention Is All You Need

* Proposed the [**Transformer**](https://arxiv.org/abs/1706.03762) architecture.
* No more explanation is needed. 



# Other Stuffs

[How to Set Up the Environment on Google Colab](https://chenglu.me/blogs/effective-colab) (in Simplified Chinese)

[How to Ask Questions in the Least Stupid and Irrigating Way](http://www.catb.org/~esr/faqs/smart-questions.html)